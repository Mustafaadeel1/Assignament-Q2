{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mustafaadeel1/Assignament-Q2/blob/main/LangChain_RAG_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install google-auth google-auth-oauthlib google-auth-httplib2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhb2LpMQQFSE",
        "outputId": "b8fc5c2c-052f-4f06-b664-c605b98fa9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.10/dist-packages (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-httplib2) (0.22.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2>=0.19.0->google-auth-httplib2) (3.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/my-gemini-api-444713-fac594037688.json\""
      ],
      "metadata": {
        "id": "trwwtk-7QM-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%pip install -qU langchain-pinecone langchain-google-genai"
      ],
      "metadata": {
        "id": "ciFdjevmJrpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66efce72-6331-426f-d78f-0aa4b512fe11"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.display import Markdown, display\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "pinecone_api_key = userdata.get('03APIKEY')\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n"
      ],
      "metadata": {
        "id": "TvCJA5SOJw1p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"practise-rag\"\n",
        "pc.delete_index(index_name)\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric='cosine',\n",
        "    spec  = ServerlessSpec(cloud=\"aws\",region=\"us-east-1\"),\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "nyBTdUgCJz0B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import os\n",
        "\n",
        "GEMINI_KEY = userdata.get(\"GOOGLE_API_2.0\")\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\", google_api_key = GEMINI_KEY)"
      ],
      "metadata": {
        "id": "aLFd3FeCP_o3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vector = embeddings.embed_query(\"Thanks To Allah 7th Time run\")"
      ],
      "metadata": {
        "id": "_10hDAPlQpHP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-t7obZQQ3k4",
        "outputId": "dfd27530-a56e-4e1b-9cde-e4f205fe947a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.021536385640501976,\n",
              " -0.008258498273789883,\n",
              " -0.024666937068104744,\n",
              " -0.007488536648452282,\n",
              " 0.03480295464396477,\n",
              " -0.010281002148985863,\n",
              " 0.04205457493662834,\n",
              " -0.02350606396794319,\n",
              " 0.025906207039952278,\n",
              " 0.025753257796168327]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "FOqR0riyQ7MU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I have chocolate chip pancake and scrambled eggs for breakfast\",\n",
        "    metadata={\"source\": \"personal\", \"meal\": \"breakfast\"}\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"LangChain is a framework for building applications with LLMs (Large Language Models), such as GPT. It provides tools to manage chains, agents, and memory for building more advanced AI applications.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"AI Framework\"}\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Agentic AI refers to autonomous AI systems that are capable of decision-making, learning, and adaptation in real-world environments without needing constant human intervention.\",\n",
        "    metadata={\"topic\": \"Agentic AI\", \"category\": \"Artificial Intelligence\", \"importance\": \"High\"}\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"In the latest world news, a new tech company has developed an innovative AI that is able to solve real-world problems faster than previous models, pushing the boundaries of automation and efficiency.\",\n",
        "    metadata={\"topic\": \"Tech News\", \"date\": \"2025-01-02\", \"company\": \"Innovative AI Company\"}\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"The use of AI in healthcare is growing rapidly. Recent advancements in diagnostic AI tools are helping doctors identify diseases more accurately and faster, significantly improving patient outcomes.\",\n",
        "    metadata={\"topic\": \"Healthcare AI\", \"category\": \"Medical Technology\", \"impact\": \"Positive\"}\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"LangChain offers a wide range of tools to work with LLMs. This includes support for document search, question-answering systems, and memory management to make intelligent agents more effective in real-world tasks.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"AI Tools\", \"use_case\": \"Advanced workflows\"}\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"Agentic AI is becoming increasingly important in industries like autonomous vehicles, robotics, and smart cities, where real-time decision-making and adaptability are crucial for success.\",\n",
        "    metadata={\"topic\": \"Agentic AI\", \"category\": \"Industry Applications\", \"industries\": [\"Autonomous Vehicles\", \"Robotics\", \"Smart Cities\"]}\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"A new world record has been set for the fastest internet speed, with researchers breaking through previous limitations using advanced fiber-optic technology, promising faster and more efficient global communication.\",\n",
        "    metadata={\"topic\": \"Tech News\", \"category\": \"Innovation\", \"record\": \"Fastest Internet Speed\", \"date\": \"2025-01-02\"}\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"In a recent study, AI-powered chatbots have been shown to outperform human customer service agents in resolving technical issues, reducing wait times and improving customer satisfaction.\",\n",
        "    metadata={\"topic\": \"AI in Customer Service\", \"category\": \"Business Technology\", \"impact\": \"High\"}\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"LangChain continues to evolve with new integrations, including support for databases, APIs, and external data sources, enabling more complex and efficient workflows for AI applications.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"Development\", \"features\": [\"Database Integration\", \"API Support\", \"External Data Sources\"]}\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1, document_2, document_3, document_4, document_5,\n",
        "    document_6, document_7, document_8, document_9, document_10\n",
        "]\n"
      ],
      "metadata": {
        "id": "T4q4VzY9RFBc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(  documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLzOhTxfRJGh",
        "outputId": "8071d083-fcd5-4e2b-a49e-1b086c55c64a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from uuid import uuid4\n",
        "uuid4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S_Py7uGROKV",
        "outputId": "8e1a7027-b20d-410c-c89c-b7964a331c0e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UUID('c8e240e0-5699-4054-a74c-7514f56bcb55')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "uuids = [str(uuid4()) for i in range (len(documents))]\n",
        "vector_store.add_documents(documents=documents, ids=uuids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sP1R640tRRDK",
        "outputId": "86cdef55-754b-4f84-b4f9-ccc11444b09a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['34b7c545-b420-4a01-a9d4-9dce4b742048',\n",
              " '9825d927-4b0f-4840-af08-e6847e03edaf',\n",
              " '2990d068-94fb-43b5-b2b8-7a3670237074',\n",
              " 'd1f47875-51b4-461a-855a-c60260f0fa64',\n",
              " 'b6606e85-64c5-4a79-8e28-94dc9e4551c2',\n",
              " 'f2cb9300-1f55-403e-8591-6b9b10998c70',\n",
              " '4ba5191c-3c4e-4a82-b274-abad92a05957',\n",
              " '57d4c88c-957f-432a-804c-699ddc8fe460',\n",
              " 'f6bee7fa-9d94-4271-8f97-9d3009c7b6af',\n",
              " '9a4ccd89-e7fe-4985-9c25-39a267be6257']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vector_result = vector_store.similarity_search(\n",
        "    \"What is agentic AI?\", k=7\n",
        ")\n",
        "print(vector_result[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv0otHDmRUsC",
        "outputId": "d53c31a8-c577-45df-dc03-bb39cc47c193"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agentic AI refers to autonomous AI systems that are capable of decision-making, learning, and adaptation in real-world environments without needing constant human intervention.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n"
      ],
      "metadata": {
        "id": "VISQNjvXRZUn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_answer(question):\n",
        "\n",
        "  vector_result = vector_store.similarity_search(question, k=5)\n",
        "\n",
        "  llm = ChatGoogleGenerativeAI(\n",
        "      api_key=GEMINI_KEY,\n",
        "      model = \"gemini-2.0-flash-exp\",\n",
        "      max_tokens= 100,\n",
        "      temperature=0.7\n",
        "  )\n",
        "\n",
        "  prompt1= PromptTemplate(\n",
        "      input_variables=[\"question\"],\n",
        "      template = \"Using this data {vector_result} . Answer the following question: \\n\\n{question}\"\n",
        "  )\n",
        "  chain1= prompt1 | llm\n",
        "\n",
        "  final_answer = chain1.invoke({\"vector_result\": vector_result, \"question\": question})\n",
        "\n",
        "  return final_answer"
      ],
      "metadata": {
        "id": "ssPIQsZGRgHK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = user_answer(\"What's the latest news?\")\n"
      ],
      "metadata": {
        "id": "mpchzrsvRjKq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "-qJLX7y4Rl5l",
        "outputId": "83caac6f-8b3c-4d9b-dfe7-d2dce054d206"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the provided documents, here's a summary of the latest news:\n\n*   **Innovative AI:** A new tech company has developed an AI that can solve real-world problems faster than previous models.\n*   **Fastest Internet Speed:** A new world record has been set for the fastest internet speed using advanced fiber-optic technology.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response_1 = user_answer(\"What is Langchain and where it is used ?\")"
      ],
      "metadata": {
        "id": "ldYE9cE4Ro4L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "display(Markdown(response_1.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "qn2gm7LYRsCc",
        "outputId": "31c7ddb4-684e-4310-eae2-4b2776782b07"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the provided documents, here's an answer to your question:\n\n**What is LangChain?**\n\nLangChain is a framework designed to help build applications that utilize Large Language Models (LLMs), such as GPT. It provides tools for managing chains of operations, creating agents, and handling memory. This allows for the development of more advanced AI applications.\n\n**Where is LangChain used?**\n\nLangChain is used in various ways to enhance AI applications. Specifically, it enables"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response_2 = user_answer(\"What i like in breakfast , Tell me in Key points\")"
      ],
      "metadata": {
        "id": "GNyDA6EbRvgD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "display(Markdown(response_2.content))\n"
      ],
      "metadata": {
        "id": "0_fQOO9QRyqU",
        "outputId": "33a31f34-7039-4988-e4c7-789774185578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, based on the provided data, here's what you had for breakfast, presented as key points:\n\n*   **Meal:** Chocolate chip pancake and scrambled eggs.\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNKyBcTltGF6e40lz7pQYr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}